{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-18T19:57:17.249423Z",
     "iopub.status.busy": "2021-11-18T19:57:17.249202Z",
     "iopub.status.idle": "2021-11-18T19:57:19.133518Z",
     "shell.execute_reply": "2021-11-18T19:57:19.133178Z",
     "shell.execute_reply.started": "2021-11-18T19:57:17.249372Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "HomeDir = '../'\n",
    "DataDir = HomeDir+'data/'\n",
    "ListDir = HomeDir+'lists/'\n",
    "ListResDir = HomeDir+'lists/sim/'\n",
    "\n",
    "import astropy.units as u\n",
    "from astropy import constants as const\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy.coordinates import Angle\n",
    "import healpy as hp\n",
    "import numpy as np\n",
    "import math\n",
    "import copy\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from time import time as tictoc\n",
    "import pandas as pd\n",
    "import scipy\n",
    "from scipy.interpolate import griddata\n",
    "from scipy import interpolate\n",
    "from scipy import integrate\n",
    "import os\n",
    "import sys\n",
    "import importlib\n",
    "from scipy.optimize import fsolve\n",
    "import scipy.stats as st\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "from IPython.display import display, clear_output\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "np.set_printoptions(edgeitems=3, linewidth=200) \n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('max_rows',200) and pandas.set_option('max_columns',20)\n",
    "\n",
    "from MyUnits import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class for the sky patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-18T19:57:19.134781Z",
     "iopub.status.busy": "2021-11-18T19:57:19.134679Z",
     "iopub.status.idle": "2021-11-18T19:57:19.138537Z",
     "shell.execute_reply": "2021-11-18T19:57:19.138202Z",
     "shell.execute_reply.started": "2021-11-18T19:57:19.134768Z"
    }
   },
   "outputs": [],
   "source": [
    "class sky_patch:\n",
    "    \"\"\"Class defining the stellar target properties. Notice that this works only for a disk on the sky.\"\"\"\n",
    "    def __init__(self, center_ra, center_dec, disc_radius, distance, data_file_name, mu_bcrs=np.array([0,0])):\n",
    "        self.center_ra = center_ra\n",
    "        self.center_dec = center_dec\n",
    "        self.disc_radius = disc_radius\n",
    "        self.distance = distance # distance from the observer\n",
    "        ### galactic coordinates of the center (in deg)\n",
    "        self.center_l = SkyCoord(center_ra*u.deg, center_dec*u.deg, frame = 'icrs').galactic.l.radian/degree \n",
    "        self.center_b = SkyCoord(center_ra*u.deg, center_dec*u.deg, frame = 'icrs').galactic.b.radian/degree \n",
    "        ### solid angle covered by the stellar target (in radians)\n",
    "        self.delta_omega = 2*np.pi*(1-math.cos(disc_radius)) #np.pi*disc_radius**2   \n",
    "        ### proper motion of the stellar target in the Barycentric Celestial Reference Systems (aligned with ICRS)\n",
    "        self.mu_bcrs = mu_bcrs # in mas/y\n",
    "        self.data_file_name = data_file_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Angular separation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-18T19:57:19.139743Z",
     "iopub.status.busy": "2021-11-18T19:57:19.139641Z",
     "iopub.status.idle": "2021-11-18T19:57:19.143389Z",
     "shell.execute_reply": "2021-11-18T19:57:19.142969Z",
     "shell.execute_reply.started": "2021-11-18T19:57:19.139730Z"
    }
   },
   "outputs": [],
   "source": [
    "def angular_sep_magn_sq(ra1, dec1, ra2, dec2):\n",
    "    \"\"\"Computes the magnitude of the angular separation vector\"\"\"\n",
    "    return np.arccos(np.sin(dec1)*np.sin(dec2) + np.cos(dec1)*np.cos(dec2)*np.cos(ra2-ra1), out=np.zeros(len(ra2)), where=((ra1!=ra2) & (dec1!=dec2)) )**2\n",
    "\n",
    "def angular_sep(ra1, dec1, ra2, dec2):\n",
    "    \"\"\"Computes 2d angular separations vector for stars close to each other\"\"\"\n",
    "    return np.array([(ra1-ra2)*np.cos((dec1+dec2)/2), (dec1-dec2)]).T\n",
    "\n",
    "def angular_sep_scalar(ra1, dec1, ra2, dec2):\n",
    "    \"\"\"Computes the magnitude of the angular separation vector for stars close to each other\"\"\"\n",
    "    return np.sqrt( ((ra1-ra2)*np.cos((dec1+dec2)/2))**2 + (dec1-dec2)**2 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Equatorial to ecliptic coordinate transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From https://gea.esac.esa.int/archive/documentation/GEDR3/Gaia_archive/chap_datamodel/sec_dm_main_tables/ssec_dm_gaia_source.html and section 1.5.3 of https://www.cosmos.esa.int/documents/532822/552851/vol1_all.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-18T19:57:19.144503Z",
     "iopub.status.busy": "2021-11-18T19:57:19.144405Z",
     "iopub.status.idle": "2021-11-18T19:57:19.149349Z",
     "shell.execute_reply": "2021-11-18T19:57:19.148969Z",
     "shell.execute_reply.started": "2021-11-18T19:57:19.144490Z"
    }
   },
   "outputs": [],
   "source": [
    "rot_matrix = np.array([[1, 0, 0], [0, 0.9174821334228558, 0.39777699135300065], [0, -0.39777699135300065, 0.9174821334228558]])\n",
    "ra_offset = 0.05542*arcsec\n",
    "  \n",
    "def fn_eq_to_ecl_array(ra, dec):\n",
    "    \"\"\"Function to convert the equatorial coordinates (ra, dec) to ecliptic longitude and latitude according to the Gaia reference frame\"\"\"\n",
    "    \"\"\"Takes angle in deg and returns in deg\"\"\"    \n",
    "    ra_s, dec_s = ra*degree + ra_offset, dec*degree\n",
    "    x_vec_eq = np.array([np.cos(dec_s)*np.cos(ra_s), np.cos(dec_s)*np.sin(ra_s), np.sin(dec_s)])\n",
    "    x_vec_ecl = (rot_matrix @ x_vec_eq).T\n",
    "    \n",
    "    if np.isscalar(ra):\n",
    "        ecl_lon, ecl_lat = (np.arctan2(x_vec_ecl[1], x_vec_ecl[0])), np.arctan2(x_vec_ecl[2], np.sqrt(x_vec_ecl[0]**2 + x_vec_ecl[1]**2))\n",
    "        ecl_lon = ecl_lon + 2*np.pi*np.heaviside(-ecl_lon, 0) ### shift the interval from [-pi, pi] to [0, 2*pi]        \n",
    "    else:\n",
    "        ecl_lon, ecl_lat = (np.arctan2(x_vec_ecl[:, 1], x_vec_ecl[:, 0])), np.arctan2(x_vec_ecl[:, 2], np.sqrt(x_vec_ecl[:, 0]**2 + x_vec_ecl[:, 1]**2))\n",
    "        ecl_lon = ecl_lon + 2*np.pi*np.heaviside(-ecl_lon, 0) ### shift the interval from [-pi, pi] to [0, 2*pi]\n",
    "\n",
    "    return ecl_lon/degree, ecl_lat/degree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Healpy map and list of neighbors for each pixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-18T19:57:19.150136Z",
     "iopub.status.busy": "2021-11-18T19:57:19.150039Z",
     "iopub.status.idle": "2021-11-18T19:57:19.153077Z",
     "shell.execute_reply": "2021-11-18T19:57:19.152726Z",
     "shell.execute_reply.started": "2021-11-18T19:57:19.150123Z"
    }
   },
   "outputs": [],
   "source": [
    "def fn_nb_pixel(patch_pix, radius_nb, nside, nest=True):\n",
    "    \"\"\"For healpy pixels in the 1d array patch_pix returns the neighbors of each pixel (disc of radius radius_nb in rad)\"\"\"    \n",
    "    ### Cartesian vectors for each pixel in patch_pix\n",
    "    vec_pix_x, vec_pix_y, vec_pix_z = hp.pix2vec(nside, patch_pix, nest=nest) \n",
    "    vec_array = np.array([vec_pix_x, vec_pix_y, vec_pix_z]).T\n",
    "    \n",
    "    ### Loop over pixels\n",
    "    nb_pix = []; \n",
    "    for i in range(len(patch_pix)):\n",
    "        ### Disc around the pixel position  \n",
    "        nb_pix.append(hp.query_disc(nside, vec_array[i], radius_nb, inclusive=True, nest=nest))      \n",
    "    return nb_pix\n",
    "\n",
    "### Notice that search_around_sky is not faster than this function if we need to query neighbors within 0.1-0.3 degree. Healpy pixelation is more efficient in that case. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beta_t optimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-18T19:57:19.153741Z",
     "iopub.status.busy": "2021-11-18T19:57:19.153653Z",
     "iopub.status.idle": "2021-11-18T19:57:19.158958Z",
     "shell.execute_reply": "2021-11-18T19:57:19.158512Z",
     "shell.execute_reply.started": "2021-11-18T19:57:19.153729Z"
    }
   },
   "outputs": [],
   "source": [
    "rs_MW = 18*kpc ### r_s parameter of the NFW profile of the Milky Way (scale radius)\n",
    "rho_s_MW = 0.003*MSolar/pc**3 ### rho_s  parameter of the NFW profile of the Milky Way (scale density)\n",
    "d_Sun = 8.29*kpc ### distance of the Sun from the Galactic Center\n",
    "\n",
    "def fn_rho_dm(dist, l, b): ### works with scalar quantities\n",
    "    \"\"\"Dark matter energy density at distance dist and in the direction (l, b), given in Galactic coordinates\"\"\"\n",
    "    r_vec_sun = np.array([0, d_Sun, 0]) ### 3d vector position of the Sun wrt the Galactic Center    \n",
    "    r_vec = dist*np.array([np.sin(l)*np.cos(b), np.cos(l)*np.cos(b), np.sin(b)]) - r_vec_sun ### 3d vector wrt the Galactic Center\n",
    "    r_over_rs = np.linalg.norm(r_vec/rs_MW)\n",
    "    \n",
    "    return 4*rho_s_MW/(r_over_rs*(1+r_over_rs)**2)\n",
    "\n",
    "def fn_rho_dm_array(dist, l, b): ### works with numpy arrays \n",
    "    \"\"\"Dark matter energy density at distance dist and in the direction (l, b), given in Galactic coordinates\"\"\"\n",
    "    r_vec_sun = np.full((len(dist), 3), np.array([0, d_Sun, 0])) ### 3d vector position of the Sun wrt the Galactic Center  \n",
    "    r_vec = np.array([dist*np.sin(l)*np.cos(b) - r_vec_sun[:, 0],\n",
    "                      dist*np.cos(l)*np.cos(b) - r_vec_sun[:, 1],\n",
    "                      dist*np.sin(b) - r_vec_sun[:, 2]]).T  ### 3d vector wrt the Galactic Center\n",
    "    r_over_rs = np.linalg.norm(r_vec/rs_MW, axis=1)\n",
    "    \n",
    "    return 4*rho_s_MW/(r_over_rs*(1+r_over_rs)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-18T19:57:19.159958Z",
     "iopub.status.busy": "2021-11-18T19:57:19.159853Z",
     "iopub.status.idle": "2021-11-18T19:57:19.164434Z",
     "shell.execute_reply": "2021-11-18T19:57:19.163994Z",
     "shell.execute_reply.started": "2021-11-18T19:57:19.159945Z"
    }
   },
   "outputs": [],
   "source": [
    "def fn_n_lens(M_l, f_l, dist, l, b, delta_omega):\n",
    "    \"\"\"Average number of lenses with mass M_l and fractional abundance f_l in front of a stellar target centered at Galactic Coordinates (l, b) and covering a solid angle delta_omega, up to a distance dist\"\"\"\n",
    "    integrand = lambda dist: dist**2*fn_rho_dm(dist, l, b) ### function to be integrated over distance        \n",
    "    return delta_omega*f_l*integrate.quad(integrand, 0, dist)[0]/M_l\n",
    "\n",
    "def fn_n_lens_tot(M_l, f_l, dist, sky_patches, dist_max=False):\n",
    "    \"\"\"Total number of lenses in front of all the sky patches up to a distance dist, if dist_max=False\"\"\"\n",
    "    \"\"\"If dist_max=True, the distance is set to the distance of the stellar target for each patch\"\"\"\n",
    "    n_lens_tot = 0\n",
    "        \n",
    "    for i in range(len(sky_patches)):\n",
    "        if dist_max==False:\n",
    "            n_lens_tot += fn_n_lens(M_l, f_l, dist, sky_patches[i].center_l*degree, sky_patches[i].center_b*degree, sky_patches[i].delta_omega)    \n",
    "        else:\n",
    "            n_lens_tot += fn_n_lens(M_l, f_l, sky_patches[i].distance, sky_patches[i].center_l*degree, sky_patches[i].center_b*degree, sky_patches[i].delta_omega)    \n",
    "            \n",
    "    return n_lens_tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-18T19:57:19.165287Z",
     "iopub.status.busy": "2021-11-18T19:57:19.165152Z",
     "iopub.status.idle": "2021-11-18T19:57:19.172647Z",
     "shell.execute_reply": "2021-11-18T19:57:19.171218Z",
     "shell.execute_reply.started": "2021-11-18T19:57:19.165270Z"
    }
   },
   "outputs": [],
   "source": [
    "def fn_beta_t_opt(M_l, r_l, f_l, sky_patches):\n",
    "    \"\"\"Find the beta_t optimal for the given lens population parameters and the given stellar targets\"\"\"\n",
    "    n_lens_opt = 3 ### number of optimal lenses with beta_t >= beta_t_optimal\n",
    "    n_lens_max = fn_n_lens_tot(M_l, f_l, 0, sky_patches, dist_max=True) ### total number of lenses in front of the stellar targets\n",
    "        \n",
    "    if n_lens_max>=n_lens_opt:\n",
    "        d_min_list = np.zeros((len(sky_patches)))        \n",
    "        for i in range(len(sky_patches)):\n",
    "            d_min_list[i] = (3*M_l/(sky_patches[i].delta_omega*rho_s_MW))**(1/3)\n",
    "        dist_solve = lambda d : (fn_n_lens_tot(M_l, f_l, d, sky_patches, dist_max=False) - n_lens_opt)\n",
    "        d_opt = fsolve(dist_solve, np.min(d_min_list))[0] # solve for dist_solve==0, starting from the minimum distance at which there is one lens\n",
    "    else:\n",
    "        ### take the average of the distance to each patch on the sky\n",
    "        d_opt = 0\n",
    "        for i in range(len(sky_patches)):\n",
    "            d_opt += sky_patches[i].distance\n",
    "        d_opt = d_opt/len(sky_patches)\n",
    "        \n",
    "    return r_l/d_opt ### optimal beta_t in radians"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lens population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-18T19:57:19.390349Z",
     "iopub.status.busy": "2021-11-18T19:57:19.389890Z",
     "iopub.status.idle": "2021-11-18T19:57:19.411315Z",
     "shell.execute_reply": "2021-11-18T19:57:19.409822Z",
     "shell.execute_reply.started": "2021-11-18T19:57:19.390322Z"
    }
   },
   "outputs": [],
   "source": [
    "v0_ss = 238*1000*Meter/Second ### Solar System velocity, i.e. the observer velocity wrt the DM halo\n",
    "sigma_vl = 166*1000*Meter/Second #v0_ss/math.sqrt(2) ### Dark Matter velocity dispersion\n",
    "\n",
    "def fn_3d_unit_vec(th, phi):\n",
    "    \"\"\"Unit vector in 3d\"\"\"\n",
    "    return np.array([np.sin(th)*np.cos(phi), np.sin(th)*np.sin(phi), np.cos(th)]).T\n",
    "\n",
    "def fn_lens_population(M_l, f_l, sky_patch):\n",
    "    \"\"\"Generate a random population of lenses in front of the stellar target\"\"\"\n",
    "    ### Random number of lenses in front of the stellar target with Poisson distribution\n",
    "    n_lens_avg = fn_n_lens(M_l, f_l, sky_patch.distance, sky_patch.center_l*degree, sky_patch.center_b*degree, sky_patch.delta_omega)    \n",
    "    n_lens = np.random.poisson(n_lens_avg)\n",
    "    \n",
    "    ### Probability distribution function for the polar angle theta within the region covered by the stellar target\n",
    "    class pdf_theta(st.rv_continuous):\n",
    "        def _pdf(self, th):\n",
    "            return np.sin(th)/(1-np.cos(sky_patch.disc_radius))\n",
    "    theta_dist = pdf_theta(a=0, b=sky_patch.disc_radius, name='pdf_theta')\n",
    "\n",
    "    ### Random lens position in front of the stellar target\n",
    "    theta_lens = theta_dist.rvs(size=n_lens)\n",
    "    phi_lens = np.random.uniform(0, 2*np.pi, n_lens)\n",
    "    ### Rotation in the direction of the stellar target\n",
    "    vec_center_patch = fn_3d_unit_vec(np.pi/2-sky_patch.center_dec*degree, sky_patch.center_ra*degree)\n",
    "    rot_unit_vector = np.cross(np.array([0, 0, 1]), vec_center_patch) ### direction of the rotation axis, must be normalized\n",
    "    rot_unit_vector = rot_unit_vector/np.sqrt(rot_unit_vector[0]**2 + rot_unit_vector[1]**2 + rot_unit_vector[2]**2)\n",
    "    rot_matrix = R.from_rotvec(np.arccos(np.dot(np.array([0, 0, 1]), vec_center_patch)) * rot_unit_vector)\n",
    "\n",
    "    rot_lens_vectors = rot_matrix.apply(fn_3d_unit_vec(theta_lens, phi_lens))\n",
    "    lens_ra = (np.arctan2(rot_lens_vectors[:, 1], rot_lens_vectors[:, 0]))/degree\n",
    "    lens_dec = (np.pi/2-np.arctan2(np.sqrt(rot_lens_vectors[:, 0]**2 + rot_lens_vectors[:, 1]**2), rot_lens_vectors[:, 2]))/degree \n",
    "        \n",
    "    ### Random lens velocities\n",
    "    vl_ra = np.random.normal(0, sigma_vl, n_lens)\n",
    "    vl_dec = np.random.normal(0, sigma_vl, n_lens)\n",
    "        \n",
    "    ### Probability distribution function for the lens distance, assuming the DM energy density along the line of sight towards the center of the stellar target    \n",
    "    class pdf_dist(st.rv_continuous):\n",
    "        def _pdf(self, d):\n",
    "            return 1/n_lens_avg*sky_patch.delta_omega*f_l*d**2*fn_rho_dm(d, sky_patch.center_l*degree, sky_patch.center_b*degree)/M_l \n",
    "    d_dist = pdf_dist(a=0, b=sky_patch.distance, name='pdf_dist')\n",
    "    \n",
    "    dl = d_dist.rvs(size=n_lens)/kpc\n",
    "    \n",
    "    return n_lens, np.array([lens_ra, lens_dec, vl_ra, vl_dec, dl]).T  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noise injection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a list of stars, compute the pm and parallax noise and update the stars pm and parallax.\n",
    "\n",
    "Strategy:\n",
    "- Start from the stars after the first cleaning, but before the iterative background field subtraction. Use the columns (pmra_sub, pmdec_sub, parallax_sub).\n",
    "- Inject the noise by computing the noise PDFs in different g magnitude and radial bins and extract random values for (pm_ra, pm_dec, parallax).\n",
    "- Save the mock proper motion and parallax in the new columns (pmra_sim, pmdec_sim, parallax_sim)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-18T19:57:20.483282Z",
     "iopub.status.busy": "2021-11-18T19:57:20.482659Z",
     "iopub.status.idle": "2021-11-18T19:57:20.517727Z",
     "shell.execute_reply": "2021-11-18T19:57:20.516416Z",
     "shell.execute_reply.started": "2021-11-18T19:57:20.483207Z"
    }
   },
   "outputs": [],
   "source": [
    "def fn_noise_inj(data, disc_center, gmag_bin_size=0.1, rad_bin_size=1, noise=True):\n",
    "    \"\"\"Data-driven injectiong of the proper motion and parallax noise\"\"\"\n",
    "    ### Simulated pm_ra, pm_dec, and parallax\n",
    "    pmra_sim, pmdec_sim, parallax_sim = np.zeros(len(data)), np.zeros(len(data)), np.zeros(len(data))    \n",
    "\n",
    "    if noise:\n",
    "        print('Injecting the data-driven noise..')\n",
    "        ### Bin in g magnitude \n",
    "        data_g = data['phot_g_mean_mag'].to_numpy()\n",
    "        min_g, max_g = np.min(data_g), np.max(data_g)\n",
    "        ### Using g magnitude bins with approximately equal number of stars per bin, to avoid bins with a low number of stars    \n",
    "        n_bins_g = int(np.ceil((max_g-min_g)/gmag_bin_size))\n",
    "        bins_g = np.interp(np.linspace(0, len(data_g+1), n_bins_g + 1), np.arange(len(data_g)+1), np.append(np.sort(data_g), max_g*1.001))  # make sure that the last bin includes max_g\n",
    "        q_bin_g = np.digitize(data_g, bins_g)-1         \n",
    "\n",
    "        ### Bin in radial distance from the center        \n",
    "        center_sky_coord = SkyCoord(ra = disc_center[0] * u.deg, dec = disc_center[1] * u.deg)\n",
    "        data_sky_coord = SkyCoord(ra = data['ra'].to_numpy() * u.deg, dec = data['dec'].to_numpy() * u.deg)\n",
    "        data_r = data_sky_coord.separation(center_sky_coord).value\n",
    "        bins_r = np.arange(0, np.max(data_r)+rad_bin_size, rad_bin_size)\n",
    "        q_bin_r = np.digitize(data_r, bins_r)-1     \n",
    "        \n",
    "        ### Group the stars according to their g mag and radial position\n",
    "        df_groupby = pd.DataFrame({'q_bin_g':q_bin_g, 'q_bin_r':q_bin_r,\n",
    "                                   'pmra_sub':data['pmra_sub'].to_numpy(), 'pmdec_sub':data['pmdec_sub'].to_numpy(),\n",
    "                                   'parallax_sub':data['parallax_sub'].to_numpy()}).groupby(by=['q_bin_g', 'q_bin_r'], as_index=False)        \n",
    "         \n",
    "        n_bins = 80 ### number of bins to build the PDFs\n",
    "\n",
    "        for r in np.arange(np.min(q_bin_r), np.max(q_bin_r)+1):\n",
    "            for g in np.arange(np.min(q_bin_g), np.max(q_bin_g)+1):\n",
    "                data_group = df_groupby.get_group((g, r))\n",
    "                group_index = np.array(list(data_group.index)) # indices for the stars in this group\n",
    "                n_stars = len(data_group)\n",
    "\n",
    "                pdf_pmra, pmra_edges = np.histogram(data_group['pmra_sub'].to_numpy(), bins=n_bins, density=True)\n",
    "                pdf_pmdec, pmdec_edges = np.histogram(data_group['pmdec_sub'].to_numpy(), bins=n_bins, density=True)\n",
    "                pdf_parallax, parallax_edges = np.histogram(data_group['parallax_sub'].to_numpy(), bins=n_bins, density=True)\n",
    "\n",
    "                bin_step_pmra = pmra_edges[1:] - pmra_edges[:-1]\n",
    "                bin_step_pmdec = pmdec_edges[1:] - pmdec_edges[:-1]\n",
    "                bin_step_par = parallax_edges[1:] - parallax_edges[:-1]\n",
    "\n",
    "                ### Get the CDFs and interpolate the inverse CDFs\n",
    "                cdf_pmra = np.cumsum(pdf_pmra)*bin_step_pmra\n",
    "                inv_cdf_pmra = scipy.interpolate.interp1d(cdf_pmra, pmra_edges[1:])\n",
    "                pmra_sim[group_index] = inv_cdf_pmra(np.random.uniform(cdf_pmra[0], cdf_pmra[-1], n_stars))\n",
    "\n",
    "                cdf_pmdec = np.cumsum(pdf_pmdec)*bin_step_pmdec\n",
    "                inv_cdf_pmdec = scipy.interpolate.interp1d(cdf_pmdec, pmdec_edges[1:])\n",
    "                pmdec_sim[group_index] = inv_cdf_pmdec(np.random.uniform(cdf_pmdec[0], cdf_pmdec[-1], n_stars))\n",
    "\n",
    "                cdf_par = np.cumsum(pdf_parallax)*bin_step_par\n",
    "                inv_cdf_par = scipy.interpolate.interp1d(cdf_par, parallax_edges[1:])\n",
    "                parallax_sim[group_index] = inv_cdf_par(np.random.uniform(cdf_par[0], cdf_par[-1], n_stars))            \n",
    "    else:\n",
    "        print('Skipping noise injection. Setting stars proper motion and parallax to zero.')\n",
    "\n",
    "    ### Add columns for the simulated pm and parallax\n",
    "    data.insert(len(data.columns), 'pmra_sim', pmra_sim)\n",
    "    data.insert(len(data.columns), 'pmdec_sim', pmdec_sim)\n",
    "    data.insert(len(data.columns), 'parallax_sim', parallax_sim)\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Signal injection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observer and star velocity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-18T19:57:21.466245Z",
     "iopub.status.busy": "2021-11-18T19:57:21.465670Z",
     "iopub.status.idle": "2021-11-18T19:57:21.482424Z",
     "shell.execute_reply": "2021-11-18T19:57:21.481527Z",
     "shell.execute_reply.started": "2021-11-18T19:57:21.466179Z"
    }
   },
   "outputs": [],
   "source": [
    "### The velocity of the observer in given by the velocity of the Sun in a reference frame where the galaxy is at rest:\n",
    "### v_sun = 238 Km/s in the direction l = 270 deg, b = 0 (in Galactic coordinates)\n",
    "### or alpha = 138 deg, dec = -48.33 deg (in Equatorial coordinates)\n",
    "### Check i.e. with:\n",
    "### v_sun_dir = SkyCoord(v_sun_ra*u.rad, v_sun_dec*u.rad)\n",
    "### v_sun_dir.galactic\n",
    "\n",
    "v_sun = 238*math.pow(10,3)*Meter/Second ### magnitude of the Sun velocity\n",
    "v_sun_ra, v_sun_dec = 138.00438151*degree, -48.32963721*degree ### direction of the Sun velocity in equatorial coordnates\n",
    "v_obs = v_sun*fn_3d_unit_vec(np.pi/2-v_sun_dec, v_sun_ra)\n",
    "\n",
    "def fn_obs_vel(ra, dec):\n",
    "    \"\"\"Returns the observer velocity perpendicular to the line of sight towards the direction (ra, dec)\"\"\"\n",
    "    theta, phi = np.pi/2 - dec, ra\n",
    "    u_th = np.array([np.cos(theta)*np.cos(phi), np.cos(theta)*np.sin(phi), -np.sin(theta)]).T\n",
    "    if np.isscalar(theta):\n",
    "        u_phi = np.array([-np.sin(phi), np.cos(phi), 0]).T\n",
    "    else:\n",
    "        u_phi = np.array([-np.sin(phi), np.cos(phi), np.zeros(len(theta))]).T\n",
    "\n",
    "    return np.array([np.inner(v_obs, u_phi), -np.inner(v_obs, u_th)]).T\n",
    "\n",
    "### The velocity of the star in a reference frame where the galaxy is at rest is given by \n",
    "### the proper motion of the stellar target in the Barycentric Celestial Reference Systems (aligned with ICRS)\n",
    "### multiplied by the stellar target distance and added to the observer velocity with rispect to the Galactic center,\n",
    "### as computed by the function fn_obs_vel\n",
    "\n",
    "def fn_star_vel(v_obs, mu_star_bcrs, distance):\n",
    "    \"\"\"Returns the star velocity with respect to the galactic center\"\"\"\n",
    "    return mu_star_bcrs*distance + v_obs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matched filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-18T19:57:21.870244Z",
     "iopub.status.busy": "2021-11-18T19:57:21.869900Z",
     "iopub.status.idle": "2021-11-18T19:57:21.914368Z",
     "shell.execute_reply": "2021-11-18T19:57:21.913457Z",
     "shell.execute_reply.started": "2021-11-18T19:57:21.870211Z"
    }
   },
   "outputs": [],
   "source": [
    "# Uploading lists for the G_0 function and it's derivative. G_0 is the enclosed lens mass within a cylinder oriented along the line of sight. \n",
    "# See Eq.(3.10)=(3.11) of 1804.01991 or Eq.(2) of 2002.01938\n",
    "# For the NFW truncated lens profile given by Eq.(3) of 2002.01938 the enclosed mass cannot be computed analytically. We use an interpolation function.\n",
    "\n",
    "logxG0_list = np.loadtxt(ListDir+'G0NFWtrunc.txt');  logxG0_prime_list = np.loadtxt(ListDir+'G0pNFWtrunc.txt');  #logxG0_second_list = np.loadtxt(ListDir+'G0ppNFWtrunc.txt');\n",
    "logG0_fnc = interpolate.interp1d(logxG0_list[:, 0], logxG0_list[:, 1], kind='cubic', bounds_error=False, fill_value=(logxG0_list[0, 1], logxG0_list[-1, 1]))\n",
    "logG0_p_fnc = interpolate.interp1d(logxG0_prime_list[:, 0], logxG0_prime_list[:, 1], kind='cubic', bounds_error=False, fill_value=(logxG0_prime_list[0, 1], logxG0_prime_list[-1, 1]))\n",
    "\n",
    "\"Returns the lens enclosed mass within the distance x = beta/beta_l\"\n",
    "def G0_fnc(x): return np.power(10, logG0_fnc(np.log10(x+1E-20)))\n",
    "def G0_p_fnc(x): return np.power(10, logG0_p_fnc(np.log10(x+1E-20)))\n",
    "\n",
    "def dipole_mf(b_l, b_vec):\n",
    "    \"\"\"Returns the pm dipole-like profile from Eq.(2) of 2002.01938\"\"\"\n",
    "    b_norm = np.sqrt(b_vec[:, 0]**2 + b_vec[:, 1]**2)\n",
    "    b_hat = np.array([b_vec[:,0]/(b_norm+1E-20), b_vec[:,1]/(b_norm+1E-20)]).T; x = b_norm/b_l\n",
    "    G0_over_xsq = G0_fnc(x)/(x**2+1E-20); G0p_over_x = G0_p_fnc(x)/(x+1E-20)\n",
    "\n",
    "    remove_inf = np.heaviside(b_norm, 0) # set to zero values corresponding to b_vec = [0, 0], remove infinity at the origin\n",
    "    \n",
    "    dipole_ra = np.array([(G0_over_xsq*(2*b_hat[:, 0]*b_hat[:, 0] - 1) - G0p_over_x*b_hat[:,0]*b_hat[:,0])*remove_inf, \n",
    "                          (G0_over_xsq*(2*b_hat[:, 1]*b_hat[:, 0]) - G0p_over_x*b_hat[:, 1]*b_hat[:, 0])*remove_inf]).T\n",
    "    dipole_dec = np.array([(G0_over_xsq*(2*b_hat[:, 0]*b_hat[:, 1]) - G0p_over_x*b_hat[:, 1]*b_hat[:, 0])*remove_inf, \n",
    "                           (G0_over_xsq*(2*b_hat[:, 1]*b_hat[:, 1] - 1) - G0p_over_x*b_hat[:, 1]*b_hat[:, 1])*remove_inf]).T\n",
    "    isotropic_dipole_magn = (G0_over_xsq**2 + 0.5*(G0p_over_x**2-2*G0_over_xsq*G0p_over_x))*remove_inf # for the normalization; see Eq. (13) of 2002.01938\n",
    "            \n",
    "    return dipole_ra, dipole_dec, isotropic_dipole_magn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-18T19:57:22.411074Z",
     "iopub.status.busy": "2021-11-18T19:57:22.410334Z",
     "iopub.status.idle": "2021-11-18T19:57:22.424885Z",
     "shell.execute_reply": "2021-11-18T19:57:22.423693Z",
     "shell.execute_reply.started": "2021-11-18T19:57:22.410999Z"
    }
   },
   "outputs": [],
   "source": [
    "def parallax_mf(b_l, b_vec, sinb):\n",
    "    \"\"\"Returns the parallax profile\"\"\"\n",
    "    b_norm = np.sqrt(b_vec[:, 0]**2 + b_vec[:, 1]**2)\n",
    "    b_hat = np.array([b_vec[:,0]/(b_norm+1E-20), b_vec[:,1]/(b_norm+1E-20)]).T; x = b_norm/b_l\n",
    "    G0_over_xsq = G0_fnc(x)/(x**2+1E-20); G0p_over_x = G0_p_fnc(x)/(x+1E-20)\n",
    "       \n",
    "    return -(G0_over_xsq*(2*b_hat[:, 1]**2-1)*(1-sinb**2) + G0p_over_x*(1 - (1-sinb**2)*b_hat[:, 1]**2))/(1+sinb**2)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Signal injection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Goal: given a list of lenses and a list of stars in a specific field of view, compute the lens-induced proper motion and parallax and add it to the stars' pm.\n",
    "\n",
    "Strategy:\n",
    "- start from the simulated stars after noise injection\n",
    "- fill in a sparse array of zero pm for each pixel and add the lens correction for each lens using the template mask\n",
    "- update the list of stars adding the lens-corrected proper motion to the noise, based on their location on the grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-18T19:57:23.390041Z",
     "iopub.status.busy": "2021-11-18T19:57:23.389697Z",
     "iopub.status.idle": "2021-11-18T19:57:23.436795Z",
     "shell.execute_reply": "2021-11-18T19:57:23.435671Z",
     "shell.execute_reply.started": "2021-11-18T19:57:23.390003Z"
    }
   },
   "outputs": [],
   "source": [
    "def fn_signal_inj(data, M_l, r_l, n_lens, lens_pop, sim_sky_patch, n_betat, min_beta_t=0.002*degree):\n",
    "    \"\"\"Returns the data with the signal given by the lenses in lens_pop added to the columns pmra_sim, pmdec_sim, and parallax_sim\"\"\"\n",
    "    \n",
    "    data_ra, data_dec = data['ra'].to_numpy(), data['dec'].to_numpy()\n",
    "    data_ecl_lon, data_ecl_lat = data['ecl_lon'].to_numpy(), data['ecl_lat'].to_numpy()\n",
    "    data_pmra_sim, data_pmdec_sim, data_parallax_sim = np.zeros((len(data))), np.zeros((len(data))), np.zeros((len(data))) \n",
    "    \n",
    "    if n_lens==1:\n",
    "        vec_lens_array = hp.ang2vec(lens_pop[0], lens_pop[1], lonlat=True) # vector for the location of the lense\n",
    "\n",
    "        v_obs_lens = fn_obs_vel(lens_pop[0]*degree, lens_pop[1]*degree)\n",
    "        v_star_lens = fn_star_vel(v_obs_lens, sim_sky_patch.mu_bcrs*mas/Year, sim_sky_patch.distance)\n",
    "        Dl_over_Di = lens_pop[4]*kpc/sim_sky_patch.distance\n",
    "        vil_ra = lens_pop[2] - (1-Dl_over_Di)*v_obs_lens[0] - Dl_over_Di*v_star_lens[0]\n",
    "        vil_dec = lens_pop[3] - (1-Dl_over_Di)*v_obs_lens[1] - Dl_over_Di*v_star_lens[1]\n",
    "        beta_l = r_l/(lens_pop[4]*kpc)\n",
    "\n",
    "        lens_pop_ecl_lon, lens_pop_ecl_lat = fn_eq_to_ecl_array(lens_pop[0], lens_pop[1]) # convert into ecliptic coordinates for the parallax template\n",
    "\n",
    "        ### To find the stars around the lens use a pixelation scale of size approx. beta_l/10 and keep stars withing n_betat*beta_l\n",
    "        max_beta_l = max(beta_l, min_beta_t)\n",
    "        n = round(math.log(np.sqrt(np.pi/3)/(0.1*max_beta_l), 2)); nside = 2**n; \n",
    "        q_pix = np.asarray(hp.ang2pix(nside, data_ra, data_dec, nest=True, lonlat=True)) \n",
    "\n",
    "        ### Find stars around the lens\n",
    "        nb_lens_i = hp.query_disc(nside, vec_lens_array, n_betat*max_beta_l, inclusive=True, nest=True)\n",
    "        stars_in = ((q_pix >= nb_lens_i[0]) & (q_pix <= nb_lens_i[-1])) # first reduce the total number of stars\n",
    "        nb_stars = np.isin(q_pix[stars_in], nb_lens_i, assume_unique=False, invert=False) # keep only stars within the neighboring pixels  \n",
    "\n",
    "        ### Proper motion template\n",
    "        beta_it = angular_sep(lens_pop[0]*degree, lens_pop[1]*degree, data_ra[stars_in][nb_stars]*degree, data_dec[stars_in][nb_stars]*degree)\n",
    "        mura_tilde, mudec_tilde, mu_sq = dipole_mf(beta_l, beta_it)\n",
    "        mu_signal = (1-Dl_over_Di)*4*GN*M_l*vil_ra/r_l**2*mura_tilde/(mas/Year) + (1-Dl_over_Di)*4*GN*M_l*vil_dec/r_l**2*mudec_tilde/(mas/Year) # in mas/y\n",
    "\n",
    "        data_pmra_sim[np.where(stars_in)[0][nb_stars]] += mu_signal[:, 0] # this way of accessing the elements of data_pmra_sim does not make a copy of the array\n",
    "        data_pmdec_sim[np.where(stars_in)[0][nb_stars]] += mu_signal[:, 1]\n",
    "\n",
    "        ### Parallax template\n",
    "        beta_it_ecl = angular_sep(lens_pop_ecl_lon*degree, lens_pop_ecl_lat*degree, data_ecl_lon[stars_in][nb_stars]*degree, data_ecl_lat[stars_in][nb_stars]*degree)\n",
    "        par_t = parallax_mf(beta_l, beta_it_ecl, np.sin(lens_pop_ecl_lat*degree)) \n",
    "\n",
    "        data_parallax_sim[np.where(stars_in)[0][nb_stars]] += (1-Dl_over_Di)*4*GN*M_l*AU/r_l**2*par_t/mas # in mas\n",
    "        \n",
    "    else:    \n",
    "        vec_lens_array = hp.ang2vec(lens_pop[:, 0], lens_pop[:, 1], lonlat=True) # vector for the location of the lenses\n",
    "\n",
    "        v_obs_lens = fn_obs_vel(lens_pop[:, 0]*degree, lens_pop[:, 1]*degree)\n",
    "        v_star_lens = fn_star_vel(v_obs_lens, sim_sky_patch.mu_bcrs*mas/Year, sim_sky_patch.distance)\n",
    "        Dl_over_Di = lens_pop[:, 4]*kpc/sim_sky_patch.distance\n",
    "        vil_ra = lens_pop[:, 2] - (1-Dl_over_Di)*v_obs_lens[:, 0] - Dl_over_Di*v_star_lens[:, 0]\n",
    "        vil_dec = lens_pop[:, 3] - (1-Dl_over_Di)*v_obs_lens[:, 1] - Dl_over_Di*v_star_lens[:, 1]\n",
    "        beta_l = r_l/(lens_pop[:, 4]*kpc)\n",
    "\n",
    "        lens_pop_ecl_lon, lens_pop_ecl_lat = fn_eq_to_ecl_array(lens_pop[:, 0], lens_pop[:, 1]) # convert into ecliptic coordinates for the parallax template\n",
    "\n",
    "        ### To find the stars around each lens use a pixelation scale of size approx. max(beta_l)/10 and keep stars withing n_betat*max(beta_l)\n",
    "        max_beta_l = max(np.max(beta_l), min_beta_t)\n",
    "        n = round(math.log(np.sqrt(np.pi/3)/(0.1*max_beta_l), 2)); nside = 2**n; \n",
    "        q_pix = np.asarray(hp.ang2pix(nside, data_ra, data_dec, nest=True, lonlat=True)) \n",
    "\n",
    "        for i, l in enumerate(lens_pop):\n",
    "            ### Find stars around the lens\n",
    "            nb_lens_i = hp.query_disc(nside, vec_lens_array[i], n_betat*max_beta_l, inclusive=True, nest=True)\n",
    "            stars_in = ((q_pix >= nb_lens_i[0]) & (q_pix <= nb_lens_i[-1])) # first reduce the total number of stars\n",
    "            nb_stars = np.isin(q_pix[stars_in], nb_lens_i, assume_unique=False, invert=False) # keep only stars within the neighboring pixels  \n",
    "\n",
    "            ### Proper motion template\n",
    "            beta_it = angular_sep(lens_pop[i, 0]*degree, lens_pop[i, 1]*degree, data_ra[stars_in][nb_stars]*degree, data_dec[stars_in][nb_stars]*degree)\n",
    "            mura_tilde, mudec_tilde, mu_sq = dipole_mf(beta_l[i], beta_it)\n",
    "            mu_signal = (1-Dl_over_Di[i])*4*GN*M_l*vil_ra[i]/r_l**2*mura_tilde/(mas/Year) + (1-Dl_over_Di[i])*4*GN*M_l*vil_dec[i]/r_l**2*mudec_tilde/(mas/Year) # in mas/y\n",
    "\n",
    "            data_pmra_sim[np.where(stars_in)[0][nb_stars]] += mu_signal[:, 0] # this way of accessing the elements of data_pmra_sim does not make a copy of the array\n",
    "            data_pmdec_sim[np.where(stars_in)[0][nb_stars]] += mu_signal[:, 1]\n",
    "\n",
    "            ### Parallax template\n",
    "            beta_it_ecl = angular_sep(lens_pop_ecl_lon[i]*degree, lens_pop_ecl_lat[i]*degree, data_ecl_lon[stars_in][nb_stars]*degree, data_ecl_lat[stars_in][nb_stars]*degree)\n",
    "            par_t = parallax_mf(beta_l[i], beta_it_ecl, np.sin(lens_pop_ecl_lat[i]*degree)) \n",
    "\n",
    "            data_parallax_sim[np.where(stars_in)[0][nb_stars]] += (1-Dl_over_Di[i])*4*GN*M_l*AU/r_l**2*par_t/mas # in mas\n",
    "   \n",
    "    ### Add signal to the data\n",
    "    data['pmra_sim'] += data_pmra_sim; data['pmdec_sim'] += data_pmdec_sim; data['parallax_sim'] += data_parallax_sim; \n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-23T22:05:37.434318Z",
     "iopub.status.busy": "2021-06-23T22:05:37.433932Z",
     "iopub.status.idle": "2021-06-23T22:05:37.438613Z",
     "shell.execute_reply": "2021-06-23T22:05:37.437694Z",
     "shell.execute_reply.started": "2021-06-23T22:05:37.434215Z"
    }
   },
   "source": [
    "## Proper motion field subtraction - functions edited to work for the simulated quantities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-18T19:57:23.946672Z",
     "iopub.status.busy": "2021-11-18T19:57:23.946291Z",
     "iopub.status.idle": "2021-11-18T19:57:23.958278Z",
     "shell.execute_reply": "2021-11-18T19:57:23.956639Z",
     "shell.execute_reply.started": "2021-11-18T19:57:23.946629Z"
    }
   },
   "outputs": [],
   "source": [
    "def fn_prepare_back_sub(data, disc_center, disc_radius, beta_kernel_sub):\n",
    "    \"\"\"Prepare the data for the background motion subtraction\"\"\"\n",
    "    ### Pixelation at approx 1/3 of beta_kernel\n",
    "    n = round(math.log(np.sqrt(np.pi/3)/(beta_kernel_sub/3), 2))   \n",
    "    nside = 2**n; npix = hp.nside2npix(nside);\n",
    "\n",
    "    vec = hp.pix2vec(nside, hp.ang2pix(nside, disc_center[0], disc_center[1], nest=True, lonlat=True), nest=True)\n",
    "    disc_pix = hp.query_disc(nside, vec, disc_radius, nest=True, inclusive=True) # pixels on the sky within the selected disc\n",
    "    \n",
    "    ### Stars healpy pixel number\n",
    "    q_pix = np.asarray(hp.ang2pix(nside, data['ra'].to_numpy(), data['dec'].to_numpy(), nest=True, lonlat=True)) # healpy pixel number of the stars\n",
    "    data.loc[:, ('q_pix_{}'.format(n))] = q_pix    \n",
    "    \n",
    "    ### Find neighboring pixels for each pixel\n",
    "    nb_pixel_list = fn_nb_pixel(disc_pix, 3*beta_kernel_sub, nside, nest=True)\n",
    "\n",
    "    return disc_pix, nb_pixel_list, n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-18T19:57:24.302950Z",
     "iopub.status.busy": "2021-11-18T19:57:24.302378Z",
     "iopub.status.idle": "2021-11-18T19:57:24.338219Z",
     "shell.execute_reply": "2021-11-18T19:57:24.337186Z",
     "shell.execute_reply.started": "2021-11-18T19:57:24.302882Z"
    }
   },
   "outputs": [],
   "source": [
    "def fn_back_field_sub(data, disc_pix, nb_pixel_array, n, beta_kernel=0.1*degree):\n",
    "    \"\"\"Creates a local map of the pm field and the parallax using a gaussian distance kenerl and subtracts the mean fields from each star pm and parallax\"\"\"\n",
    "    \n",
    "    nside = 2**n; npix = hp.nside2npix(nside);\n",
    "    \n",
    "    ### Pixelate stars using dataframe groupby\n",
    "    old_pmra = data['pmra_sim'].to_numpy(); old_pmdec = data['pmdec_sim'].to_numpy(); old_parallax = data['parallax_sim'].to_numpy();\n",
    "    data.drop(labels=['pmra_sim', 'pmdec_sim', 'parallax_sim'], axis=\"columns\", inplace=True) \n",
    "\n",
    "    df_hist = pd.DataFrame({'q_pix_{}'.format(n):data['q_pix_{}'.format(n)].to_numpy(), \n",
    "                            'ra':data['ra'].to_numpy(), 'dec':data['dec'].to_numpy(),\n",
    "                            'weighted_pmra':old_pmra/data['pmra_error'].to_numpy()**2, \n",
    "                            'weighted_pmdec':old_pmdec/data['pmdec_error'].to_numpy()**2, \n",
    "                            'weighted_parallax':old_parallax/data['parallax_error'].to_numpy()**2,\n",
    "                            'pmra_w':1/data['pmra_error'].to_numpy()**2, 'pmdec_w':1/data['pmdec_error'].to_numpy()**2,\n",
    "                            'parallax_w':1/data['parallax_error'].to_numpy()**2}).groupby(by=['q_pix_{}'.format(n)], as_index=False).sum()\n",
    "            \n",
    "    occ_pix = df_hist['q_pix_{}'.format(n)].to_numpy() # uniquely occupied pixels\n",
    "    pix_count = np.bincount(data['q_pix_{}'.format(n)].to_numpy()); # number of stars per pixel  \n",
    "    filled_pix_count = pix_count[pix_count>0]\n",
    "    \n",
    "    ### Full sky pixel arrays\n",
    "    disc_pix_ra, disc_pix_dec = hp.pix2ang(nside, disc_pix, nest=True, lonlat=True) # coordinates of the selected pixels\n",
    "    all_mean_coord = np.zeros((npix, 2)); \n",
    "    all_mean_coord[disc_pix] = np.array([disc_pix_ra, disc_pix_dec]).T # set pix coordinates to the pix center\n",
    "    all_mean_coord[occ_pix] = np.array([df_hist['ra'].to_numpy()/filled_pix_count, df_hist['dec'].to_numpy()/filled_pix_count]).T # set pix coordinates to the mean coordinate\n",
    "\n",
    "    all_mean_pm = np.zeros((npix, 2)); all_mean_parallax = np.zeros(npix) \n",
    "    all_mean_pm[occ_pix] = np.array([df_hist['weighted_pmra'].to_numpy()/df_hist['pmra_w'].to_numpy(), \n",
    "                                     df_hist['weighted_pmdec'].to_numpy()/df_hist['pmdec_w'].to_numpy()]).T    \n",
    "    all_mean_parallax[occ_pix] = df_hist['weighted_parallax'].to_numpy()/df_hist['parallax_w'].to_numpy()\n",
    "    \n",
    "    n_disc_pix = len(disc_pix)\n",
    "    pm_gauss = np.zeros((n_disc_pix, 2)); parallax_gauss = np.zeros(n_disc_pix)\n",
    "\n",
    "    ### Loop over pixels\n",
    "    for i in range(n_disc_pix):\n",
    "        nb_pix = nb_pixel_array[i]     \n",
    "        rel_distance_sq = angular_sep_magn_sq(all_mean_coord[disc_pix[i], 0]*degree, all_mean_coord[disc_pix[i], 1]*degree, \n",
    "                                              all_mean_coord[nb_pix, 0]*degree, all_mean_coord[nb_pix, 1]*degree)/(2*beta_kernel**2)\n",
    "        gauss_weights = np.exp(-rel_distance_sq); sum_gauss_weights = sum(gauss_weights)\n",
    "        pm_gauss[i, 0] = sum(all_mean_pm[nb_pix, 0]*gauss_weights)/sum_gauss_weights  # gaussian weighted mean pm in ra\n",
    "        pm_gauss[i, 1] = sum(all_mean_pm[nb_pix, 1]*gauss_weights)/sum_gauss_weights  # gaussian weighted mean pm in dec\n",
    "        parallax_gauss[i] = sum(all_mean_parallax[nb_pix]*gauss_weights)/sum_gauss_weights\n",
    "        \n",
    "    ### Interpolation of the velocity field\n",
    "    pmra_interp = griddata((all_mean_coord[disc_pix, 0], all_mean_coord[disc_pix, 1]), pm_gauss[:, 0], (data['ra'].to_numpy(), data['dec'].to_numpy()), method='linear', fill_value=0)\n",
    "    pmdec_interp = griddata((all_mean_coord[disc_pix, 0], all_mean_coord[disc_pix, 1]), pm_gauss[:, 1], (data['ra'].to_numpy(), data['dec'].to_numpy()), method='linear', fill_value=0)\n",
    "    parallax_interp = griddata((all_mean_coord[disc_pix, 0], all_mean_coord[disc_pix, 1]), parallax_gauss, (data['ra'].to_numpy(), data['dec'].to_numpy()), method='linear', fill_value=0)\n",
    "        \n",
    "    data.insert(len(data.columns), 'pmra_sim', old_pmra - pmra_interp); data.insert(len(data.columns), 'pmdec_sim', old_pmdec - pmdec_interp)\n",
    "    data.insert(len(data.columns), 'parallax_sim', old_parallax - parallax_interp); \n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-18T19:57:24.802527Z",
     "iopub.status.busy": "2021-11-18T19:57:24.801902Z",
     "iopub.status.idle": "2021-11-18T19:57:24.811687Z",
     "shell.execute_reply": "2021-11-18T19:57:24.810660Z",
     "shell.execute_reply.started": "2021-11-18T19:57:24.802451Z"
    }
   },
   "outputs": [],
   "source": [
    "def fn_rem_outliers(data, pm_esc, D_s, n_sigma_out=3):\n",
    "    \"\"\"Remove stars with pm or parallax more than n_sigma_out sigma away from the expected value\"\"\"\n",
    "    \"\"\"Returns cleaned stars and fraction of outliers removed\"\"\"\n",
    "    old_len = len(data)\n",
    "    new_data = data[( np.sqrt(data['pmra_sim'].to_numpy()**2 + data['pmdec_sim'].to_numpy()**2) < \n",
    "                      (pm_esc + n_sigma_out*np.sqrt(data['pmra_error'].to_numpy()**2 + data['pmdec_error'].to_numpy()**2)) ) &\n",
    "                    ( np.abs(data['parallax_sim'].to_numpy()) < (1/D_s + n_sigma_out*data['parallax_error'].to_numpy()) )]\n",
    "    return new_data, 1-len(new_data)/old_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-18T19:57:25.021788Z",
     "iopub.status.busy": "2021-11-18T19:57:25.021470Z",
     "iopub.status.idle": "2021-11-18T19:57:25.028982Z",
     "shell.execute_reply": "2021-11-18T19:57:25.027657Z",
     "shell.execute_reply.started": "2021-11-18T19:57:25.021756Z"
    }
   },
   "outputs": [],
   "source": [
    "def fn_rem_edges(data, disc_center, disc_radius):\n",
    "    \"\"\"Keep only stars within disc_radius of the disc_center, to remove the edges\"\"\"\n",
    "    center_sky_coord = SkyCoord(ra = disc_center[0] * u.deg, dec = disc_center[1] * u.deg)\n",
    "    data_sky_coord = SkyCoord(ra = data['ra'].to_numpy() * u.deg, dec = data['dec'].to_numpy() * u.deg)\n",
    "    data_r = data_sky_coord.separation(center_sky_coord).value*degree\n",
    "     \n",
    "    return data[data_r < disc_radius]    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Effective weights - function edited to work for the simulated quantities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-18T19:57:26.458484Z",
     "iopub.status.busy": "2021-11-18T19:57:26.457874Z",
     "iopub.status.idle": "2021-11-18T19:57:26.481688Z",
     "shell.execute_reply": "2021-11-18T19:57:26.481211Z",
     "shell.execute_reply.started": "2021-11-18T19:57:26.458413Z"
    }
   },
   "outputs": [],
   "source": [
    "def fn_effective_w(data, disc_center, gmag_bin_size=0.1, rad_bin_size=1):\n",
    "    \"\"\"Compute effective pm and parallax dispersion in gmag and radial bins\"\"\"\n",
    "    \n",
    "    ### Bin in g magnitude and radial distance from the center\n",
    "    data_g = data['phot_g_mean_mag'].to_numpy()\n",
    "    min_g, max_g = np.min(data_g), np.max(data_g)\n",
    "    #bins_g = np.arange(min_g, max_g+gmag_bin_size, gmag_bin_size)\n",
    "    ### Using g magnitude bins with approximately equal number of stars per bin, to avoid bins with a low number of stars    \n",
    "    n_bins_g = int(np.ceil((max_g-min_g)/gmag_bin_size))\n",
    "    bins_g = np.interp(np.linspace(0, len(data_g+1), n_bins_g + 1), np.arange(len(data_g)+1), np.append(np.sort(data_g), max_g*1.001))  # make sure that the last bin includes max_g\n",
    "    q_bin_g = np.digitize(data_g, bins_g)-1         \n",
    "    \n",
    "    center_sky_coord = SkyCoord(ra = disc_center[0] * u.deg, dec = disc_center[1] * u.deg)\n",
    "    data_sky_coord = SkyCoord(ra = data['ra'].to_numpy() * u.deg, dec = data['dec'].to_numpy() * u.deg)\n",
    "    data_r = data_sky_coord.separation(center_sky_coord).value\n",
    "    bins_r = np.arange(0, np.max(data_r)+rad_bin_size, rad_bin_size)\n",
    "    q_bin_r = np.digitize(data_r, bins_r)-1     \n",
    "    \n",
    "    ### Histograms with mean pm and parallax dispersion per bin\n",
    "    counts = np.histogram2d(data_g, data_r, bins=[bins_g, bins_r], weights=None)[0]\n",
    "    pm_sq = np.histogram2d(data_g, data_r, bins=[bins_g, bins_r], weights=(data['pmra_sim'].to_numpy()**2 + data['pmdec_sim'].to_numpy()**2))[0]\n",
    "    par_sq = np.histogram2d(data_g, data_r, bins=[bins_g, bins_r], weights=(data['parallax_sim'].to_numpy()**2))[0]\n",
    "\n",
    "    sigma_pm_eff_hist = np.sqrt(np.divide(pm_sq, counts, out=np.zeros_like(pm_sq), where=counts!=0))\n",
    "    sigma_par_eff_hist = np.sqrt(np.divide(par_sq, counts, out=np.zeros_like(par_sq), where=counts!=0))\n",
    "\n",
    "    ### Set to zero for bins that have less than 30 stars\n",
    "    sigma_pm_eff_hist[counts < 30] = 0\n",
    "    sigma_par_eff_hist[counts < 30] = 0\n",
    "    \n",
    "    ### Add effective error columns (for each star, take the max between the instrumental and effective dispersion)\n",
    "    data.insert(len(data.columns), 'pm_eff_error', np.max(np.array([sigma_pm_eff_hist[q_bin_g, q_bin_r], np.sqrt(data['pmra_error'].to_numpy()**2 + data['pmdec_error'].to_numpy()**2)]), axis=0))\n",
    "    data.insert(len(data.columns), 'parallax_eff_error', np.max(np.array([sigma_par_eff_hist[q_bin_g, q_bin_r], data['parallax_error'].to_numpy()]), axis=0))\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Template scan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-18T19:57:27.462183Z",
     "iopub.status.busy": "2021-11-18T19:57:27.461853Z",
     "iopub.status.idle": "2021-11-18T19:57:27.481917Z",
     "shell.execute_reply": "2021-11-18T19:57:27.481041Z",
     "shell.execute_reply.started": "2021-11-18T19:57:27.462149Z"
    }
   },
   "outputs": [],
   "source": [
    "def fn_template_scan(nside, scan_pix, q_pix):\n",
    "    \"\"\"Compute the template at the locations given by coarse_scan_pix\"\"\"\n",
    "    \"\"\"Includes pm and parallax templates\"\"\"\n",
    "        \n",
    "    scan_coord = hp.pix2ang(nside, scan_pix, nest=True, lonlat=True) # coordinates of the template locations\n",
    "    scan_coord_ecl = fn_eq_to_ecl_array(scan_coord[0], scan_coord[1]) # convert into ecliptic coordinates for the parallax template\n",
    "\n",
    "    ### Cartesian vectors for each pixel in scan_pix\n",
    "    vec_pix_x, vec_pix_y, vec_pix_z = hp.pix2vec(nside, scan_pix, nest=True) \n",
    "    vec_array = np.array([vec_pix_x, vec_pix_y, vec_pix_z]).T\n",
    "    \n",
    "    n_loc = len(scan_pix)\n",
    "    tau_mu_ra, tau_mu_dec, tau_mu_norm = np.zeros(n_loc), np.zeros(n_loc), np.zeros(n_loc)\n",
    "    tau_par, tau_par_norm = np.zeros(n_loc), np.zeros(n_loc)\n",
    "    \n",
    "    for i in range(n_loc):\n",
    "        nb_pix_i = hp.query_disc(nside, vec_array[i], n_betat*beta_t, inclusive=True, nest=True) # disc around the template position \n",
    "\n",
    "        stars_in = ((q_pix >= nb_pix_i[0]) & (q_pix <= nb_pix_i[-1])) # first reduce the total number of stars   \n",
    "        nb_stars = np.isin(q_pix[stars_in], nb_pix_i, assume_unique=False, invert=False) # keep only stars within the neighboring pixels \n",
    "        #nb_stars = np.intersect1d(q_pix[stars_in], nb_pix_i, assume_unique=False, return_indices=True)[1] # this does not work because it returns only the unique list of common values! we also want repeated entries\n",
    "\n",
    "        ### Pm template\n",
    "        beta_it = angular_sep(scan_coord[0][i]*degree, scan_coord[1][i]*degree, data_ra[stars_in][nb_stars]*degree, data_dec[stars_in][nb_stars]*degree)\n",
    "        mu_ra, mu_dec, mu_sq = dipole_mf(beta_t, beta_it)\n",
    "\n",
    "        tau_mu_norm[i] = np.sqrt(sum(mu_sq/pm_w_sq[stars_in][nb_stars])) ## normalization\n",
    "        tau_mu_ra[i] = sum((mu_ra[:, 0]*weighted_pmra[stars_in][nb_stars] + mu_ra[:, 1]*weighted_pmdec[stars_in][nb_stars]))\n",
    "        tau_mu_dec[i] = sum((mu_dec[:, 0]*weighted_pmra[stars_in][nb_stars] + mu_dec[:, 1]*weighted_pmdec[stars_in][nb_stars]))\n",
    "                \n",
    "        ### Parallax template\n",
    "        beta_it_ecl = angular_sep(scan_coord_ecl[0][i]*degree, scan_coord_ecl[1][i]*degree, data_ecl_lon[stars_in][nb_stars]*degree, data_ecl_lat[stars_in][nb_stars]*degree)\n",
    "        par_t = parallax_mf(beta_t, beta_it_ecl, np.sin(scan_coord_ecl[1][i]*degree)) \n",
    "        \n",
    "        tau_par_norm[i] = np.sqrt(sum(par_t**2/par_w_sq[stars_in][nb_stars])) ## normalization\n",
    "        tau_par[i] =  sum(par_t*weighted_par[stars_in][nb_stars])\n",
    "            \n",
    "    return np.array([scan_coord[0], scan_coord[1], tau_mu_ra, tau_mu_dec, tau_mu_norm, tau_par, tau_par_norm]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-18T19:57:27.960264Z",
     "iopub.status.busy": "2021-11-18T19:57:27.959693Z",
     "iopub.status.idle": "2021-11-18T19:57:27.983942Z",
     "shell.execute_reply": "2021-11-18T19:57:27.982534Z",
     "shell.execute_reply.started": "2021-11-18T19:57:27.960199Z"
    }
   },
   "outputs": [],
   "source": [
    "def fn_chi_sq(M_l, r_l, beta_t, tau_values):\n",
    "    \"\"\"Returns the chi_sq (optimal global test statistic) for each of the tau_values. The minimum should be retained.\"\"\"\n",
    "    \"\"\"Returns the location, the beta_t value and the chi_sq including both the proper motion and parallax templates and the proper motion only\"\"\"\n",
    "    [ind_ra, ind_dec, ind_tau_ra, ind_tau_dec, ind_n, ind_tau_par, ind_par_n] = range(7)\n",
    "    ### Converting to natural units\n",
    "    n_mu_list = tau_values[:, ind_n]*(Year/mas) \n",
    "    t_mu_ra_list, t_mu_dec_list = tau_values[:, ind_tau_ra]*(Year/mas), tau_values[:, ind_tau_dec]*(Year/mas)\n",
    "    t_mu_sq = t_mu_ra_list**2 + t_mu_dec_list**2\n",
    "    n_p_list = tau_values[:, ind_par_n]/mas; t_p_list = tau_values[:, ind_tau_par]/mas\n",
    "    v0 = -fn_obs_vel(tau_values[:, ind_ra]*degree, tau_values[:, ind_dec]*degree) # prefered direction for the velocity template\n",
    "    v0_sq = v0[:, 0]**2 + v0[:, 1]**2\n",
    "    tau_dot_v0 = t_mu_ra_list*v0[:, 0] + t_mu_dec_list*v0[:, 1] \n",
    "\n",
    "    tau_skycoord = SkyCoord(tau_values[:, ind_ra]*u.deg, tau_values[:, ind_dec]*u.deg)\n",
    "    rho_beta_t_contr = -2*np.log(r_l**3/M_l*fn_rho_dm_array(np.full(len(tau_values), r_l)/beta_t, tau_skycoord.galactic.l.rad, tau_skycoord.galactic.b.rad)/beta_t**4)\n",
    "    \n",
    "    C_l = 4*GN*M_l/r_l**2\n",
    "    Cl_sigmav_Nmu = C_l*sigma_vl*n_mu_list\n",
    "    t_mu_sq_over_n_sq = np.divide(t_mu_sq, n_mu_list**2, out=np.zeros_like(n_mu_list), where=n_mu_list!=0)\n",
    "    tau_dot_over_n = np.divide(tau_dot_v0, n_mu_list*sigma_vl, out=np.zeros_like(n_mu_list), where=n_mu_list!=0)\n",
    "    mu_templ_contr = -(Cl_sigmav_Nmu)/(1+Cl_sigmav_Nmu**2)*( Cl_sigmav_Nmu*(t_mu_sq_over_n_sq - v0_sq/sigma_vl**2) + 2*tau_dot_over_n )\n",
    "           \n",
    "    Cl_Au_Np = C_l*AU*n_p_list\n",
    "    t_p_over_n = np.divide(t_p_list, n_p_list, out=np.zeros_like(n_p_list), where=n_p_list!=0)\n",
    "    p_templ_contr = -2*Cl_Au_Np*( t_p_over_n - Cl_Au_Np/2 )\n",
    "    \n",
    "    return np.array([tau_values[:, ind_ra], tau_values[:, ind_dec], np.full((len(tau_values)), beta_t), rho_beta_t_contr + mu_templ_contr + p_templ_contr, rho_beta_t_contr + mu_templ_contr]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation template analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-18T19:57:28.581899Z",
     "iopub.status.busy": "2021-11-18T19:57:28.581313Z",
     "iopub.status.idle": "2021-11-18T19:57:28.609017Z",
     "shell.execute_reply": "2021-11-18T19:57:28.607894Z",
     "shell.execute_reply.started": "2021-11-18T19:57:28.581833Z"
    }
   },
   "outputs": [],
   "source": [
    "def fn_run_analysis(beta_t, M_l, r_l, n_lens, lens_pop):\n",
    "    \"\"\"Computes the templates for the given value of beta_t and the given list of lenses. Returns the list of chi^2 for each location.\"\"\"\n",
    "    ### Coarse pixelation scale\n",
    "    n_coarse = math.ceil(math.log(np.sqrt(np.pi/3)/beta_t, 2)); npix_coarse = hp.nside2npix(2**n_coarse); \n",
    "    beta_pix_coarse = np.sqrt(4*np.pi / npix_coarse)    \n",
    "    \n",
    "    ### Take 5 locations around the lens (ra, dec) where to compute the template using the step of the fine pixelation\n",
    "    ### Taking 20 locations per lens\n",
    "    beta_steps = np.array([-2, -1, 0, 1, 2])*beta_step*beta_pix_coarse/degree\n",
    "    template_scan_ra, template_scan_dec = [], []\n",
    "\n",
    "    if n_lens==1:\n",
    "        x_list = lens_pop[0] + beta_steps/np.cos(lens_pop[1]*degree)\n",
    "        y_list = lens_pop[1] + beta_steps\n",
    "\n",
    "        xy_grid = np.meshgrid(x_list, y_list, indexing='xy')\n",
    "        x_grid_flat = xy_grid[0].flatten(); y_grid_flat = xy_grid[1].flatten()\n",
    "\n",
    "        xy_dist = angular_sep_scalar(lens_pop[0]*degree, lens_pop[1]*degree, x_grid_flat*degree, y_grid_flat*degree)\n",
    "        template_scan_ra.extend(x_grid_flat[xy_dist < beta_pix_coarse]); template_scan_dec.extend(y_grid_flat[xy_dist < beta_pix_coarse])\n",
    "        \n",
    "    else:\n",
    "        for i in range(len(lens_pop)):\n",
    "            x_list = lens_pop[i, 0] + beta_steps/np.cos(lens_pop[i, 1]*degree)\n",
    "            y_list = lens_pop[i, 1] + beta_steps\n",
    "\n",
    "            xy_grid = np.meshgrid(x_list, y_list, indexing='xy')\n",
    "            x_grid_flat = xy_grid[0].flatten(); y_grid_flat = xy_grid[1].flatten()\n",
    "\n",
    "            xy_dist = angular_sep_scalar(lens_pop[i, 0]*degree, lens_pop[i, 1]*degree, x_grid_flat*degree, y_grid_flat*degree)\n",
    "            template_scan_ra.extend(x_grid_flat[xy_dist < beta_pix_coarse]); template_scan_dec.extend(y_grid_flat[xy_dist < beta_pix_coarse])\n",
    "        \n",
    "    ### Fine pixelation of size approx. beta_t/10 (can be a bit larger than beta_t/10, so using round is fine)\n",
    "    n = round(math.log(np.sqrt(np.pi/3)/(0.1*beta_t), 2)); nside = 2**n; \n",
    "    template_scan_pix = np.unique(hp.ang2pix(nside, template_scan_ra, template_scan_dec, nest=True, lonlat=True)) \n",
    "    n_locations = len(template_scan_pix)\n",
    "\n",
    "    print('\\nTemplate scan for beta_t = '+str(beta_t/degree)+' deg.')\n",
    "    print('Number of template locations: '+str(n_locations))\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "    q_pix = np.asarray(hp.ang2pix(nside, data_ra, data_dec, nest=True, lonlat=True)) # healpy pixel number of the stars, needed to find stars near a specific template location\n",
    "    \n",
    "    ### Compute the template for \"step\" number of location\n",
    "    tau_values = fn_template_scan(nside, template_scan_pix, q_pix)\n",
    "    \n",
    "    print('Template scan completed. Computing the chi_sq...')\n",
    "    sys.stdout.flush()\n",
    "    chi_sq = fn_chi_sq(M_l, r_l, beta_t, tau_values)\n",
    "    \n",
    "    return chi_sq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-18T19:57:30.535851Z",
     "iopub.status.busy": "2021-11-18T19:57:30.535508Z",
     "iopub.status.idle": "2021-11-18T19:57:30.572036Z",
     "shell.execute_reply": "2021-11-18T19:57:30.571457Z",
     "shell.execute_reply.started": "2021-11-18T19:57:30.535817Z"
    }
   },
   "outputs": [],
   "source": [
    "tic = tictoc()\n",
    "\n",
    "### Define the sky patches used for the analysis\n",
    "### Parameters taken from Gaia Early Data Release 3: Structure and properties of the Magellanic Clouds (see Table 4)\n",
    "LMC_sky_patch = sky_patch(81.28, -69.78, 5*degree, 50*kpc, 'LMC_disc_5', np.array([1.871, 0.391]))\n",
    "SMC_sky_patch = sky_patch(12.80, -73.15, 4*degree, 60*kpc, 'SMC_disc_4', np.array([0.686, -1.237]))\n",
    "\n",
    "all_sky_patches = [LMC_sky_patch, SMC_sky_patch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-15T15:54:41.478660Z",
     "iopub.status.busy": "2021-11-15T15:54:41.477835Z",
     "iopub.status.idle": "2021-11-15T15:54:41.484893Z",
     "shell.execute_reply": "2021-11-15T15:54:41.483337Z",
     "shell.execute_reply.started": "2021-11-15T15:54:41.478567Z"
    }
   },
   "outputs": [],
   "source": [
    "### Read in paramters from the command line\n",
    "### Example of how to run the python script with the simulation n.0 for the paramter space point (M_l, r_l, f_l) = (10^8 M_solar, 1 pc, 1)\n",
    "### python dm_simulation_script LMC 80 30 30 0\n",
    "sky_patch_name = sys.argv[1] #'LMC'\n",
    "M_l = math.pow(10, float(sys.argv[2])/10)*MSolar\n",
    "r_l = math.pow(10, (-3 + float(sys.argv[3])/10))*pc\n",
    "f_l = math.pow(10, (-3 + float(sys.argv[4])/10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-18T19:58:04.944340Z",
     "iopub.status.busy": "2021-11-18T19:58:04.943987Z",
     "iopub.status.idle": "2021-11-18T19:58:04.950293Z",
     "shell.execute_reply": "2021-11-18T19:58:04.949083Z",
     "shell.execute_reply.started": "2021-11-18T19:58:04.944300Z"
    }
   },
   "outputs": [],
   "source": [
    "### Define sky patch to use in this simulation\n",
    "if sky_patch_name == 'LMC':    \n",
    "    sim_sky_patch = LMC_sky_patch\n",
    "    print(' ********** Running the '+sys.argv[5]+'th simulation analysis on the LMC **********\\n')\n",
    "elif sky_patch_name == 'SMC':\n",
    "    sim_sky_patch = SMC_sky_patch\n",
    "    print(' ********** Running the '+sys.argv[5]+'th simulation analysis on the SMC **********\\n')\n",
    "else:\n",
    "    print('ERROR: wrong name provided for the sky patch!')\n",
    "sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-18T19:58:15.665702Z",
     "iopub.status.busy": "2021-11-18T19:58:15.665136Z",
     "iopub.status.idle": "2021-11-18T19:58:15.674278Z",
     "shell.execute_reply": "2021-11-18T19:58:15.673114Z",
     "shell.execute_reply.started": "2021-11-18T19:58:15.665637Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result will be saved in the file LMC_disc_5_80_30_32_1\n"
     ]
    }
   ],
   "source": [
    "disc_radius = sim_sky_patch.disc_radius\n",
    "disc_center = np.array([sim_sky_patch.center_ra, sim_sky_patch.center_dec])\n",
    "data_file_name = sim_sky_patch.data_file_name\n",
    "result_file_name = data_file_name+'_'+sys.argv[2]+'_'+sys.argv[3]+'_'+sys.argv[4]+'_'+sys.argv[5]\n",
    "#result_file_name = data_file_name+'_80_30_32_1'\n",
    "print('Result will be saved in the file '+result_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-18T19:58:21.404853Z",
     "iopub.status.busy": "2021-11-18T19:58:21.404521Z",
     "iopub.status.idle": "2021-11-18T19:58:21.411754Z",
     "shell.execute_reply": "2021-11-18T19:58:21.410745Z",
     "shell.execute_reply.started": "2021-11-18T19:58:21.404819Z"
    }
   },
   "outputs": [],
   "source": [
    "### Parameters for data cleaning\n",
    "beta_kernel_sub_0 = 0.1*degree; # gaussian kernel for background subtraction \n",
    "beta_kernel_sub = 0.06*degree; # 0.1*degree; gaussian kernel for background subtraction \n",
    "pm_esc = 0.2; D_s = 50; n_sigma_out_0 = 5; n_sigma_out = 3; # escape velocity, distance of the stars given in kpc, number of sigmas for outlier removal\n",
    "n_iter_sub = 3; # number of iterations for the background subtraction\n",
    "disc_radius_no_edge = disc_radius - beta_kernel_sub_0 - (n_iter_sub+1)*beta_kernel_sub\n",
    "gmag_bin_size=0.1; rad_bin_size=1 # for the effective weights\n",
    "\n",
    "n_betat=3.5;\n",
    "min_beta_t = 0.002*degree # for point-like lenses, inject signal on stars around the lens within n_betat*min_beta_t \n",
    "beta_step = 1/9; # beta_t step used in the fine pixelation, needed to determine positions around the lens locations where to compute the template\n",
    "\n",
    "n_lens_max = 200 # maximum number of the closest lenses to keep for the signal injection and analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-18T19:58:22.075784Z",
     "iopub.status.busy": "2021-11-18T19:58:22.075176Z",
     "iopub.status.idle": "2021-11-18T19:58:22.130023Z",
     "shell.execute_reply": "2021-11-18T19:58:22.128973Z",
     "shell.execute_reply.started": "2021-11-18T19:58:22.075719Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimal beta_t value: 0.00473  deg.\n",
      "Computing the template for beta_t = [0.005  0.0045 0.004 ]\n"
     ]
    }
   ],
   "source": [
    "### Load list of beta_t values and convert to radians\n",
    "beta_t_list = np.load(ListDir+'beta_t_list.npy')/10000*degree \n",
    "### Optimal value of beta_t for the lens population parameters\n",
    "beta_t_opt = fn_beta_t_opt(M_l, r_l, f_l, all_sky_patches)\n",
    "\n",
    "### Find the beta_t values from the beta_t_list closest to the optimal beta_t\n",
    "beta_t_opt_ind = np.argmin(np.abs(np.array(beta_t_list) - beta_t_opt))\n",
    "if beta_t_opt_ind==0:\n",
    "    beta_t_opt_list = beta_t_list[:beta_t_opt_ind+2]\n",
    "elif beta_t_opt_ind==(len(beta_t_list)-1):\n",
    "    beta_t_opt_list = beta_t_list[beta_t_opt_ind-1:]\n",
    "else:\n",
    "    beta_t_opt_list = beta_t_list[beta_t_opt_ind-1:beta_t_opt_ind+2]\n",
    "\n",
    "print('\\nOptimal beta_t value:', str(beta_t_opt/degree)[:7], ' deg.') \n",
    "print('Computing the template for beta_t =', str(str(beta_t_opt_list/degree)))\n",
    "sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-18T19:58:23.355853Z",
     "iopub.status.busy": "2021-11-18T19:58:23.355275Z",
     "iopub.status.idle": "2021-11-18T19:58:24.541322Z",
     "shell.execute_reply": "2021-11-18T19:58:24.540619Z",
     "shell.execute_reply.started": "2021-11-18T19:58:23.355787Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14730230, 14)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Loading the data -- loading an npy file is much faster than loading the csv file with pd.rad_csv\n",
    "data_np = np.load(DataDir+data_file_name+'_clean.npy')\n",
    "columns_df = ['ra', 'dec', 'pmra', 'pmdec', 'parallax', 'pmra_error', 'pmdec_error', 'parallax_error', 'phot_g_mean_mag', 'ecl_lon', 'ecl_lat', 'pmra_sub', 'pmdec_sub', 'parallax_sub']\n",
    "data = pd.DataFrame(data_np, columns=columns_df)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-18T19:58:33.973879Z",
     "iopub.status.busy": "2021-11-18T19:58:33.973045Z",
     "iopub.status.idle": "2021-11-18T19:58:34.210563Z",
     "shell.execute_reply": "2021-11-18T19:58:34.209676Z",
     "shell.execute_reply.started": "2021-11-18T19:58:33.973818Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 lenses in front of the stellar target.\n"
     ]
    }
   ],
   "source": [
    "### Generating the lens population\n",
    "n_lens, lens_pop = fn_lens_population(M_l, f_l, sim_sky_patch)\n",
    "print(n_lens, 'lenses in front of the stellar target.')\n",
    "sys.stdout.flush()\n",
    "\n",
    "### Sort lenses based on their distance and keep only the n_lens_max closest ones\n",
    "if n_lens > n_lens_max:\n",
    "    print(len(lens_pop), 'lenses. Retaining only the closest', n_lens_max)\n",
    "    sys.stdout.flush()\n",
    "    lens_ind_sort = np.argsort(lens_pop[:, -1])\n",
    "    lens_pop = lens_pop[lens_ind_sort[:n_lens_max]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-18T19:58:38.070239Z",
     "iopub.status.busy": "2021-11-18T19:58:38.069826Z",
     "iopub.status.idle": "2021-11-18T20:12:44.806910Z",
     "shell.execute_reply": "2021-11-18T20:12:44.803703Z",
     "shell.execute_reply.started": "2021-11-18T19:58:38.070204Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Injecting the data-driven noise..\n",
      "Injecting the signal..\n",
      "\n",
      "Background subtraction..\n",
      "Iter 0 -- fraction of outliers removed: 9.23113 %\n",
      "Iter 1 -- fraction of outliers removed: 0.02300 %\n",
      "Iter 2 -- fraction of outliers removed: 0.00914 %\n",
      "\n",
      "Template scan for beta_t = 0.005 deg.\n",
      "Number of template locations: 294\n",
      "Template scan completed. Computing the chi_sq...\n",
      "\n",
      "Template scan for beta_t = 0.0045 deg.\n",
      "Number of template locations: 294\n",
      "Template scan completed. Computing the chi_sq...\n",
      "\n",
      "Template scan for beta_t = 0.004 deg.\n",
      "Number of template locations: 294\n",
      "Template scan completed. Computing the chi_sq...\n",
      "Simulation done in 914.2507839202881 s.\n"
     ]
    }
   ],
   "source": [
    "columns_res = ['ra', 'dec', 'beta_t', 'min_chi_sq', 'min_chi_sq_mu_only']\n",
    "\n",
    "if n_lens == 0: ### If there are no lenses in front of the stellar target, skip the analysis and set the resulting chi^2 to zero\n",
    "    res_df = pd.DataFrame(np.zeros((2, 5)), columns=columns_res)\n",
    "    res_df.to_csv(ListResDir+result_file_name+'.csv', index=False)\n",
    "    toc = tictoc()    \n",
    "    print('Simulation done in', str(toc - tic), 's.')        \n",
    "    sys.stdout.flush()          \n",
    "else:\n",
    "    ### Injecting the noise\n",
    "    fn_noise_inj(data, disc_center, gmag_bin_size, rad_bin_size, noise=True)\n",
    "    print('Injecting the signal..')\n",
    "    sys.stdout.flush()\n",
    "    fn_signal_inj(data, M_l, r_l, n_lens, lens_pop, sim_sky_patch, n_betat, min_beta_t)\n",
    "    \n",
    "    ### Prepare the mock data for the iterative background subtraction and outlier removal\n",
    "    disc_pix, nb_pixel_list, n = fn_prepare_back_sub(data, disc_center, disc_radius, beta_kernel_sub)\n",
    "\n",
    "    print('\\nBackground subtraction..')\n",
    "    sys.stdout.flush()    \n",
    "    ### Iterative background subtraction and outlier removal\n",
    "    for i in range(n_iter_sub):\n",
    "        fn_back_field_sub(data, disc_pix, nb_pixel_list, n, beta_kernel=beta_kernel_sub) ### sub=True can be used only after this function has been already called once with sub=False\n",
    "        data, f_out = fn_rem_outliers(data, pm_esc, D_s, n_sigma_out)\n",
    "        print('Iter '+str(i)+' -- fraction of outliers removed: '+str(f_out*100)[:7]+' %')\n",
    "\n",
    "    fn_back_field_sub(data, disc_pix, nb_pixel_list, n, beta_kernel=beta_kernel_sub)\n",
    "\n",
    "    ### Remove stars at the boundary to avoid edge effect due to gaussian kernel field subtraction\n",
    "    data = fn_rem_edges(data, disc_center, disc_radius_no_edge)\n",
    "    \n",
    "    ### Compute the effective weights\n",
    "    fn_effective_w(data, disc_center, gmag_bin_size, rad_bin_size)\n",
    "\n",
    "    ### Quantities used to compute the template\n",
    "    data_ra, data_dec = data['ra'].to_numpy(), data['dec'].to_numpy()\n",
    "    data_ecl_lon, data_ecl_lat = data['ecl_lon'].to_numpy(), data['ecl_lat'].to_numpy()\n",
    "    pm_w_sq = (data['pm_eff_error'].to_numpy())**2\n",
    "    weighted_pmra = data['pmra_sim'].to_numpy()/data['pm_eff_error'].to_numpy()**2\n",
    "    weighted_pmdec = data['pmdec_sim'].to_numpy()/data['pm_eff_error'].to_numpy()**2\n",
    "    par_w_sq = (data['parallax_eff_error'].to_numpy())**2\n",
    "    weighted_par = data['parallax_sim'].to_numpy()/data['parallax_eff_error'].to_numpy()**2\n",
    "        \n",
    "    ### Run the analysis on the mock data to compute the template at the lens locations and compute the chi^2\n",
    "    chi_sq = [];\n",
    "    for beta_t in beta_t_opt_list:\n",
    "        chi_sq.extend(fn_run_analysis(beta_t, M_l, r_l, n_lens, lens_pop)); \n",
    "    chi_sq = np.array(chi_sq)\n",
    "    \n",
    "    ### Save the result into a file\n",
    "    res_df = pd.DataFrame(np.array([chi_sq[np.argmin(chi_sq[:, 3])], chi_sq[np.argmin(chi_sq[:, 4])]]), columns=columns_res)\n",
    "    res_df.to_csv(ListResDir+result_file_name+'.csv', index=False)\n",
    "\n",
    "    toc = tictoc()    \n",
    "    print('Simulation done in', str(toc - tic), 's.')        \n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
