{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-25T20:56:43.442511Z",
     "iopub.status.busy": "2022-01-25T20:56:43.440836Z",
     "iopub.status.idle": "2022-01-25T20:56:46.623098Z",
     "shell.execute_reply": "2022-01-25T20:56:46.622787Z",
     "shell.execute_reply.started": "2022-01-25T20:56:43.442227Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created TAP+ (v1.2.1) - Connection:\n",
      "\tHost: gea.esac.esa.int\n",
      "\tUse HTTPS: True\n",
      "\tPort: 443\n",
      "\tSSL Port: 443\n",
      "Created TAP+ (v1.2.1) - Connection:\n",
      "\tHost: geadata.esac.esa.int\n",
      "\tUse HTTPS: True\n",
      "\tPort: 443\n",
      "\tSSL Port: 443\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import astropy.units as u\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy.time import Time\n",
    "from astroquery.gaia import Gaia\n",
    "import healpy as hp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import copy\n",
    "from time import time as tictoc\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from os import listdir\n",
    "import gzip\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from time import time as tictoc\n",
    "from scipy.special import erf\n",
    "import scipy as sp\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "from IPython.display import display, clear_output\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "np.set_printoptions(edgeitems=3, linewidth=200) \n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('max_rows',200) and pandas.set_option('max_columns',20)\n",
    "\n",
    "from MyUnits import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-25T21:00:06.088660Z",
     "iopub.status.busy": "2022-01-25T21:00:06.088316Z",
     "iopub.status.idle": "2022-01-25T21:00:06.093563Z",
     "shell.execute_reply": "2022-01-25T21:00:06.092358Z",
     "shell.execute_reply.started": "2022-01-25T21:00:06.088626Z"
    }
   },
   "outputs": [],
   "source": [
    "edr3_data = '/Users/crimondino/Dropbox (PI)/MyLensVelocity2/data/gedr3_gaia_source/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Acceleration field"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function for parallel binning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-25T21:00:07.333812Z",
     "iopub.status.busy": "2022-01-25T21:00:07.333470Z",
     "iopub.status.idle": "2022-01-25T21:00:07.343779Z",
     "shell.execute_reply": "2022-01-25T21:00:07.342901Z",
     "shell.execute_reply.started": "2022-01-25T21:00:07.333778Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GaiaSource_003112-005263.csv.gz', 'GaiaSource_459543-459553.csv.gz', 'GaiaSource_006602-007952.csv.gz', 'GaiaSource_664985-665011.csv.gz', 'GaiaSource_005264-006601.csv.gz', 'GaiaSource_778885-779312.csv.gz', 'GaiaSource_000000-003111.csv.gz']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_files = listdir(edr3_data); \n",
    "list_files = [file for file in list_files if file[-7:]=='.csv.gz'] #select only files ending with 'csv.gz'\n",
    "print(list_files[0:10])\n",
    "len(list_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-25T21:00:24.532839Z",
     "iopub.status.busy": "2022-01-25T21:00:24.532385Z",
     "iopub.status.idle": "2022-01-25T21:00:24.543573Z",
     "shell.execute_reply": "2022-01-25T21:00:24.542298Z",
     "shell.execute_reply.started": "2022-01-25T21:00:24.532801Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nside = 256 , npix = 786432\n",
      "linear pixel size = 824.516  arcsec = 0.22903  degree\n"
     ]
    }
   ],
   "source": [
    "n = 8\n",
    "nside = 2**n\n",
    "fac_source_id = 2**(59-2*n)\n",
    "npix = hp.nside2npix(nside)\n",
    "print('nside =',nside,', npix =',npix)\n",
    "print('linear pixel size =',str(np.sqrt(4*np.pi / npix) / arcsec)[0:7],' arcsec =', str(np.sqrt(4*np.pi / npix) / degree)[0:7],' degree')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-25T21:00:38.256284Z",
     "iopub.status.busy": "2022-01-25T21:00:38.255896Z",
     "iopub.status.idle": "2022-01-25T21:00:38.267683Z",
     "shell.execute_reply": "2022-01-25T21:00:38.266486Z",
     "shell.execute_reply.started": "2022-01-25T21:00:38.256249Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.00000000e+03  5.00000000e-02  7.53315095e-02  1.13496727e-01  1.70997595e-01  2.57630139e-01  3.88153345e-01  5.84803548e-01  8.81082680e-01  1.32746577e+00  2.00000000e+00  1.00000000e+03]\n",
      "[ 3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22]\n"
     ]
    }
   ],
   "source": [
    "# bin definitions\n",
    "bins_parallax = np.concatenate([[-1000],np.logspace(np.log10(0.05),np.log10(2),10),[1000]])\n",
    "print(bins_parallax)\n",
    "bins_G = np.arange(3,23,1) # floor or the min and max G mag in the entire catalog are 3 and 21\n",
    "print(bins_G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_acc_stats(tab, th_count=3, return_tab=False, n_sigma_out = 3): \n",
    "    \"\"\"\n",
    "    Bins the stars in tab in healpix, G mag and parallax and computes the mean and variance of acc_ra and acc_dec per bin.\n",
    "    If return_tab=False, returns the statistic in each bin.\n",
    "    If return_tab=True, returns the stars in tab removing the outliers at more than n_sigma_out from the mean.\n",
    "    \"\"\"\n",
    "\n",
    "    ### healpix binning\n",
    "    q_pix = np.floor(tab['source_id'].to_numpy() / fac_source_id).astype(int)\n",
    "    bins_pix = np.arange(np.min(np.unique(q_pix)), np.max(np.unique(q_pix))+2,1) # should be +2 to include sources in the last bin\n",
    "    q_binpix = np.digitize(q_pix, bins_pix)-1  # need to access the histogram matrix elements\n",
    "\n",
    "    ### assign to G bins\n",
    "    tab_G = tab['phot_g_mean_mag'].to_numpy()\n",
    "    q_binG = np.digitize(tab_G, bins_G)-1      \n",
    "    \n",
    "    ### probabilistic assignment to parallax bins\n",
    "    tab_parallax = tab['parallax'].to_numpy(); tab_parallax_error = tab['parallax_error'].to_numpy();\n",
    "    prob_parallax = np.nan * np.ones((len(tab),len(bins_parallax)-1))\n",
    "    for i in range(len(bins_parallax)-1):\n",
    "        x1_list = (bins_parallax[i]-tab_parallax)/tab_parallax_error/np.sqrt(2)\n",
    "        x2_list = (bins_parallax[i+1]-tab_parallax)/tab_parallax_error/np.sqrt(2)\n",
    "        prob_parallax[:,i] = 0.5*(erf(x2_list)-erf(x1_list))\n",
    "\n",
    "    tab_acc_ra = tab['accel_ra'].to_numpy(); tab_acc_dec = tab['accel_dec'].to_numpy();\n",
    "    ### histogram of summed probabilities\n",
    "    hist_prob = sp.stats.binned_statistic_dd([tab_G,q_pix],np.transpose(prob_parallax), bins=[bins_G,bins_pix],statistic='sum')[0] \n",
    "    ### histogram of average acc_ra weighted by probabilities\n",
    "    hist_acc_ra = sp.stats.binned_statistic_dd([tab_G,q_pix],np.transpose(prob_parallax) * tab_acc_ra, bins=[bins_G,bins_pix],statistic='sum')[0] #sum first in each bin\n",
    "    hist_acc_ra = hist_acc_ra / (hist_prob + 1e-20) #then divide by number in each bin\n",
    "    hist_acc_dec = sp.stats.binned_statistic_dd([tab_G,q_pix],np.transpose(prob_parallax) * tab_acc_dec, bins=[bins_G,bins_pix],statistic='sum')[0] #sum first in each bin\n",
    "    hist_acc_dec = hist_acc_dec / (hist_prob + 1e-20) #then divide by number in each bin\n",
    "    \n",
    "    ### For each star, get the mean acc of the corresponding bin\n",
    "    mean_acc_ra = hist_acc_ra[:, q_binG, q_binpix].T; mean_acc_dec = hist_acc_dec[:, q_binG, q_binpix].T\n",
    "\n",
    "    ### histogram of acc variance weighted by parallax bin probabilities\n",
    "    hist_acc_ra_var = sp.stats.binned_statistic_dd([tab_G,q_pix],np.transpose(prob_parallax) * (mean_acc_ra.T - tab_acc_ra)**2,\n",
    "                                                   bins=[bins_G,bins_pix],statistic='sum')[0] #sum first in each bin\n",
    "    hist_acc_ra_var = hist_acc_ra_var / (hist_prob - 1 + 1e-20) # the estimator should have a -1 (this matches for example var() computed with panda's groupy)\n",
    "    hist_acc_dec_var = sp.stats.binned_statistic_dd([tab_G,q_pix],np.transpose(prob_parallax) * (mean_acc_dec.T - tab_acc_dec)**2,\n",
    "                                                    bins=[bins_G,bins_pix],statistic='sum')[0] #sum first in each bin\n",
    "    hist_acc_dec_var = hist_acc_dec_var / (hist_prob - 1 + 1e-20) \n",
    "    hist_acc_radec_var = sp.stats.binned_statistic_dd([tab_G,q_pix],np.transpose(prob_parallax) * (mean_acc_ra.T - tab_acc_ra) * (mean_acc_dec.T - tab_acc_dec),\n",
    "                                                      bins=[bins_G,bins_pix],statistic='sum')[0] #sum first in each bin\n",
    "    hist_acc_radec_var = hist_acc_radec_var / (hist_prob - 1 + 1e-20) \n",
    "    \n",
    "    ### set to nan bins where there are too few stars\n",
    "    hist_acc_ra[hist_prob < th_count] = np.nan; hist_acc_dec[hist_prob < th_count] = np.nan\n",
    "    hist_acc_ra_var[hist_prob < th_count] = np.nan; hist_acc_dec_var[hist_prob < th_count] = np.nan; hist_acc_radec_var[hist_prob < th_count] = np.nan\n",
    "\n",
    "    if return_tab==False: # returns the data frame with the statistics computed using tab\n",
    "        ###  filler for generalized bins indices\n",
    "        hist_bins_pix = np.ones(np.shape(hist_prob)) * bins_pix[:-1]\n",
    "        hist_bins_G = np.transpose(np.transpose(np.ones(np.shape(hist_prob)),axes=[0,2,1]) * bins_G[:-1],axes=[0,2,1])\n",
    "        hist_bins_parallax = np.transpose(np.transpose(np.ones(np.shape(hist_prob)),axes=[2,1,0]) * bins_parallax[:-1],axes=[2,1,0])\n",
    "\n",
    "        ###  collect data and output\n",
    "        data = np.transpose([hist_bins_pix, hist_bins_G, hist_bins_parallax, hist_prob, hist_acc_ra, hist_acc_dec, hist_acc_ra_var, hist_acc_dec_var, hist_acc_radec_var],axes=[1,2,3,0])\n",
    "        data = data.reshape(-1, data.shape[-1])\n",
    "        return pd.DataFrame(data,columns=['pix','G_bin','parallax_bin','number','mean_acc_ra','mean_acc_dec','var_acc_ra','var_acc_dec','var_acc_radec'])\n",
    "    \n",
    "    else: # returns tab where the acc outliers more than n_sigma_out away from zero have been removed\n",
    "        ### For each star, get the acc mean and variance of the corresponding bin (after excluding the low count bins)\n",
    "        mean_acc_ra = hist_acc_ra[:, q_binG, q_binpix].T; mean_acc_dec = hist_acc_dec[:, q_binG, q_binpix].T\n",
    "        var_acc_ra = hist_acc_ra_var[:, q_binG, q_binpix].T; var_acc_dec = hist_acc_dec_var[:, q_binG, q_binpix].T; var_acc_radec = hist_acc_radec_var[:, q_binG, q_binpix].T;    \n",
    "\n",
    "        ###  Get the mean and var for each star\n",
    "        tab_sum_pw = np.sum(prob_parallax, axis=1, where=(~np.isnan(mean_acc_ra)))  # sum of the parallax weights for each star using only bins with enough statistics \n",
    "        tab_mean_acc_ra = np.sum(np.nan_to_num(mean_acc_ra*prob_parallax), axis=1)/(tab_sum_pw + 1e-20)\n",
    "        tab_mean_acc_dec = np.sum(np.nan_to_num(mean_acc_dec*prob_parallax), axis=1)/(tab_sum_pw + 1e-20)\n",
    "        tab_var_acc_ra = np.sum(np.nan_to_num(var_acc_ra*prob_parallax), axis=1)/(tab_sum_pw + 1e-20)\n",
    "        tab_var_acc_dec = np.sum(np.nan_to_num(var_acc_dec*prob_parallax), axis=1)/(tab_sum_pw + 1e-20)\n",
    "        tab_var_acc_radec = np.sum(np.nan_to_num(var_acc_radec*prob_parallax), axis=1)/(tab_sum_pw + 1e-20)        \n",
    "        \n",
    "        ### Replace the effective variance with the measurement errors for stars that have 0 mean (fall into empty bins)\n",
    "        tab_var_acc_ra[tab_var_acc_ra==0] = (tab['accel_ra_error'].to_numpy()[tab_var_acc_ra==0])**2\n",
    "        tab_var_acc_dec[tab_var_acc_dec==0] = (tab['accel_dec_error'].to_numpy()[tab_var_acc_dec==0])**2\n",
    "        tab_var_acc_radec[tab_var_acc_radec==0] = (np.zeros(len(tab))*tab['accel_ra_error'].to_numpy()*tab['accel_dec_error'].to_numpy())[tab_var_acc_radec==0]\n",
    "        \n",
    "        ### subtracted acc and inverse covariance for outlier removal\n",
    "        acc_sub = np.array([tab['accel_ra'].to_numpy()-tab_mean_acc_ra, tab['accel_dec'].to_numpy()-tab_mean_acc_dec]).T\n",
    "        inv_cov_acc = np.linalg.inv(np.array([[tab_var_acc_ra, tab_var_acc_radec], [tab_var_acc_radec, tab_var_acc_dec]]).T)\n",
    "        acc_over_sigma_sq = inv_cov_acc[:, 0, 0]*acc_sub[:, 0]**2 + inv_cov_acc[:, 1, 1]*acc_sub[:, 1]**2 + 2*inv_cov_acc[:, 0, 1]*acc_sub[:, 0]*acc_sub[:, 1]\n",
    "        \n",
    "        return tab.iloc[acc_over_sigma_sq < n_sigma_out**2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-25T21:21:12.162271Z",
     "iopub.status.busy": "2022-01-25T21:21:12.160922Z",
     "iopub.status.idle": "2022-01-25T21:21:12.178058Z",
     "shell.execute_reply": "2022-01-25T21:21:12.177454Z",
     "shell.execute_reply.started": "2022-01-25T21:21:12.162191Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
