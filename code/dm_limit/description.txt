The MCs analysis do get the limit on compact DM clumps is done in several steps.

1) Download the MCs stars from the Gaia archive at https://gea.esac.esa.int/archive/ using the ADQL query:
   
   * File 'LMC_disc_5.csv' %%%'
    
        SELECT ra, dec, pmra, pmdec, parallax, pmra_error, pmdec_error, parallax_error, 
               pmra_pmdec_corr, parallax_pmra_corr, parallax_pmdec_corr, 
               phot_g_mean_mag, ruwe, ipd_gof_harmonic_amplitude, ipd_frac_multi_peak, ipd_frac_odd_win, ecl_lon, ecl_lat 
        FROM gaiaedr3.gaia_source WHERE 1=CONTAINS(POINT('ICRS',ra,dec),CIRCLE('ICRS',81.28,-69.78,5)) AND parallax/parallax_error < 5 AND 
        
   * File 'SMC_disc_4.csv

        SELECT ra, dec, pmra, pmdec, parallax, pmra_error, pmdec_error, parallax_error, 
               pmra_pmdec_corr, parallax_pmra_corr, parallax_pmdec_corr, 
               phot_g_mean_mag, ruwe, ipd_gof_harmonic_amplitude, ipd_frac_multi_peak, ipd_frac_odd_win, ecl_lon, ecl_lat FROM gaiaedr3.gaia_source 
        WHERE 1=CONTAINS(POINT('ICRS',ra,dec),CIRCLE('ICRS',12.80,-73.15,4)) AND parallax/parallax_error < 5 AND phot_g_mean_mag > 0

   You can download them from my dropbox as well:
   * LMC @ https://www.dropbox.com/s/33ivjtdr0k0u45l/LMC_disc_5.csv?dl=0
   * SMC @ https://www.dropbox.com/s/79sc5gq8euz4qwy/SMC_disc_4.csv?dl=0

2) Perform a first cleaning of the data that includes: subtracting the background field, removing over-dense clumps, removing outliers at 5 sigma, removing stars with bad astrometric fit parameters. The resulting data will be used as inputs for the simulations and are saved as data_file_name+'_clean.csv' and data_file_name+'_clean.npy' (retaining only some columns). See the notebook 'test_first_cleaning.ipynb'. 

3) Perform a second cleaning of the data that includes: subtracting the background field and removing the outliers iteratively, removing the edges, computing the effective dispersion. The resulting data will be used as inputs for the template scanning and are saved as data_file_name+'_final.csv' and data_file_name+'_final.npy' (the latter contains only columns used to compute the template, with pm and parallax already properly weighted). This cleaning will also be performed on the simulated data. See the notebook 'test_second_cleaning.ipynb'.

4) Perform the template scan for a list of beta_t values. This can be done locally for the largest values of beta_t (fewer template scan locations), but it's recommended to run it on a cluster for the entire list of beta_t's.  See the notebook 'test_template_scan.ipynb'